{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_classes_df = pd.read_csv('../input/planets-dataset/planet/planet/train_classes.csv')\ntrain_classes_df.head()\ntrain_classes_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission_df = pd.read_csv('../input/planets-dataset/planet/planet/sample_submission.csv')\nsample_submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = !ls ../input/planets-dataset/planet/planet/test-jpg | wc -l\ntest2 = !ls ../input/planets-dataset/test-jpg-additional/test-jpg-additional | wc -l\nassert sample_submission_df.shape[0] == float(test1[0])+float(test2[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from skimage import io\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_number =10\nimg = io.imread('../input/planets-dataset/planet/planet/train-jpg/train_{}.jpg'.format(image_number))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_classes_df[train_classes_df['image_name'] == 'train_10']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_labels = set()\ndef append_labels(tags):\n    for tag in tags.split():\n        unique_labels.add(tag)\n\ntrain_classes = train_classes_df.copy()\ntrain_classes['tags'].apply(append_labels)\nunique_labels = list(unique_labels)\nprint(unique_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(unique_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_classes_df.shape\n    \nn_labels = len(unique_labels)\nnew_dimension = np.prod(train_classes_df.shape[1:])\ntrain_classes_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert len(train_classes['image_name'].unique()) == train_classes.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let's do one hot encoding (vectorize) the labels in 'train_classes'\nfor tag in unique_labels:\n    train_classes[tag] = train_classes['tags'].apply(lambda x: 1 if tag in x.split() else 0)\n    \n# adding '.jpg' extension to 'image_name'\ntrain_classes['image_name'] = train_classes['image_name'].apply(lambda x: '{}.jpg'.format(x)) \ntrain_classes.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_col = list(train_classes.columns[2:]) # storing the tags column names as a variable\n\n# initializing an image generator with some data augumentation\nimage_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\n# loading images from dataframe\nX = image_gen.flow_from_dataframe(dataframe=train_classes, \\\n        directory='/kaggle/input/planets-dataset/planet/planet/train-jpg/', x_col='image_name', y_col=y_col, \\\n       target_size=(128, 128), class_mode='raw', seed=1, batch_size=128)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X is an iterable, It contains 317 batches, each batch contains 128 images and labels because \n#40479 / 128 is 316 remainder 31 each image is of shape (128, 128, 3), each label is of shape (17, )\n\n# let's abitrarily view an image\nx109 = X[0][0][109] # first batch, images, 109th image\ny109 = X[0][1][109] # first batch, labels, 109th label\nprint(\"each image's shape is {}\".format(x109.shape))\nprint(\"each label's shape is {}\".format(y109.shape))\nprint('we have {} batches'.format(len(X)))\nprint('each batch has {} images/labels'.format(X[0][0].shape[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout, Flatten, BatchNormalization, Conv2D\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom tqdm import tqdm\nfrom keras import optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fbeta(ytrue , ypred, beta=2, epsilon=1e-4):\n    beta_squarred = beta**2\n\n    ytrue = tf.cast(ytrue, tf.float32)\n    ypred = tf.cast(tf.greater(tf.cast(ypred, tf.float32), tf.constant(0.5)), tf.float32)\n        \n    tp = tf.reduce_sum(ytrue * ypred, axis=1)\n    fp = tf.reduce_sum(ypred, axis=1) - tp\n    fn = tf.reduce_sum(ytrue, axis=1) - tp\n    \n    precision = tp/(tp+fp+epsilon)\n    recall = tp/(tp+fn+epsilon)\n    \n    fb = (1+beta_squarred)*precision*recall / (beta_squarred*precision + recall + epsilon)\n    return fb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def multi_label_acc(ytrue , ypred, epsilon=1e-4):\n    \n    ytrue = tf.cast(ytrue, tf.float32)\n    ypred = tf.cast(tf.greater(tf.cast(ypred, tf.float32), tf.constant(0.5)), tf.float32)\n    \n    tp = tf.reduce_sum(ytrue * ypred, axis=1)\n    fp = tf.reduce_sum(ypred, axis=1) - tp\n    fn = tf.reduce_sum(ytrue, axis=1) - tp\n    \n    ytrue = tf.cast(ytrue, tf.bool)\n    ypred = tf.cast(ypred, tf.bool)\n    \n    tn = tf.reduce_sum(tf.cast(tf.logical_not(ytrue), tf.float32) * tf.cast(tf.logical_not(ypred), tf.float32),\\\n                       axis=1)\n    \n    return (tp+tn)/(tp+tn+fp+fn+epsilon)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size = 128\ninput_channels = 3\nepochs =  22\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(Conv2D(32, 3, 3, activation='relu', input_shape=(32, 32, 3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(48, 3, 3, activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, 3, 3, activation='relu'))\n    \n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(17, activation='sigmoid')) \n    \n    opt = Adam(lr=1e-2)\n    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[multi_label_acc, fbeta])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nnb_classes = 17\nnb_epoch = 10\nimg_rows, img_cols = 18, 18\nnb_filters = 32\npool_size = (2, 2)\nkernel_size = (3, 3)\ninput_shape = (1, 18,18)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    Sequential()\nmodel.add(Dense(256, activation='relu', input_shape=(new_dimension,)))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(no_labels, activation='softmax'))\n\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_best_check_point = ModelCheckpoint(filepath='best_model.hdf5', monitor='val_fbeta', \\\n                                        mode='max', save_best_only=True, save_weights_only=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255,validation_split=0.2)\n\n# generating the 80% training image data\ntrain_gen = train_image_gen.flow_from_dataframe(dataframe=train_classes, \\\n        directory='../input/planets-dataset/planet/planet/train-jpg/', x_col='image_name', y_col=y_col, \\\n       target_size=(128, 128), class_mode='raw', seed=0, batch_size=128, subset='training')\n\n# generating the 20% validation image data\nval_gen = train_image_gen.flow_from_dataframe(dataframe=train_classes, \\\n        directory='../input/planets-dataset/planet/planet/train-jpg/', x_col='image_name', y_col=y_col, \\\n       target_size=(128, 128), class_mode='raw', seed=0, batch_size=128, subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# setting step size for training and validation image data\nstep_train_size = int(np.ceil(train_gen.samples / train_gen.batch_size))\nstep_val_size = int(np.ceil(val_gen.samples / train_gen.batch_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"step_train_size+step_val_size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Turn on GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = build_model() # building a sequential model for training\n\n# fitting the model\nmodel1.fit(x=train_gen, steps_per_epoch=step_train_size, validation_data=val_gen, validation_steps=step_val_size,\n         epochs=epochs, callbacks=[save_best_check_point])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adding .jpg extension to 'image_name' in sample_submission data\nsample_submission = sample_submission_df.copy()\nsample_submission['image_name'] = sample_submission['image_name'].apply(lambda x: '{}.jpg'.format(x))\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting the first 40669 'image_name'(s) from the submission_sample dataframe to generate image data from \n# test.jpg folder\ntest1_df = sample_submission.iloc[:40669]['image_name'].reset_index().drop('index', axis=1)\ntest1_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initializing an image data generator object for the first 40669 images in the sample submission dataframe\ntest_image_gen1 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\n# generating the image data for the first 40669 images in the sample submission dataframe\ntest_gen1 = test_image_gen1.flow_from_dataframe(dataframe=test1_df, \\\n            directory='../input/planets-dataset/planet/planet/test-jpg/', x_col='image_name', y_col=None, \\\n            batch_size=128, shuffle=False, class_mode=None, target_size=(128, 128))\n\n# setting the step size for the testing set for the first 40669 images in the sample submission dataframe\nstep_test_size1 = int(np.ceil(test_gen1.samples / test_gen1.batch_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = build_model() # building a sequential model for training\ntest_gen1.reset() # reseting the generator to be sure of avoiding shuffling\npred1 = model2.predict(test_gen1, steps=step_test_size1, verbose=1) # predicts the first 40669 images in the \n                                                                    # sample submission dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_file_names1 = test_gen1.filenames # storing the filenames (images names) of the first 40669 images names in \n                                       # the sample submission dataframe as ordered in the prediction as a \n                                       # variable\n        \n# converting the predictions of the first 40669 to tag names\npred_tags1 = pd.DataFrame(pred1)\npred_tags1 = pred_tags1.apply(lambda x: ' '.join(np.array(unique_labels)[x > 0.5]), axis=1)\n\n# converting the predictions of the first 40669 to a dataframe\nresult1 = pd.DataFrame({'image_name': test_file_names1, 'tags': pred_tags1})\nresult1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting the remaining 'image_name'(s) from the submission_sample dataframe to generate image data from \n# test-additional.jpg folder\ntest2_df = sample_submission.iloc[40669:]['image_name'].reset_index().drop('index', axis=1)\ntest2_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# initializing an image data generator object for the remaining images in the sample submission dataframe\ntest_image_gen2 = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)\n\n# generating the image data for the remaining images in the sample submission dataframe\ntest_gen2 = test_image_gen2.flow_from_dataframe(dataframe=test2_df, \\\n            directory='../input/planets-dataset/test-jpg-additional/test-jpg-additional/', x_col='image_name', \\\n            y_col=None, batch_size=128, shuffle=False, class_mode=None, target_size=(128, 128))\n\n# setting the step size for the testing set for the remaining images in the sample submission dataframe\nstep_test_size2 = int(np.ceil(test_gen2.samples / test_gen2.batch_size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_gen2.reset() # reseting the generator to be sure of avoiding shuffling\npred2 = model2.predict(test_gen2, steps=step_test_size2, verbose=1) # predicts the remaining images in the \n                                                                    # sample submission dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_file_names2 = test_gen2.filenames # storing the filenames (images names) of the remaining images names in \n                                       # the sample submission dataframe as ordered in the prediction as a \n                                       # variable\n        \n# converting the predictions of the remaining images to tag names\npred_tags2 = pd.DataFrame(pred2)\npred_tags2 = pred_tags2.apply(lambda x: ' '.join(np.array(unique_labels)[x > 0.5]), axis=1)\n\n# converting the predictions of the remaining to a dataframe\nresult2 = pd.DataFrame({'image_name': test_file_names2, 'tags': pred_tags2})\nresult2.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_result = pd.concat([result1, result2]) # concatenate the predictions of the test.jpg and \n                                             # test-additional.jpg into a single dataframe\n    \nfinal_result = final_result.reset_index().drop('index', axis=1) # reseting the index of the dataframe so it \n                                                                # matches that of sample submission datafarme\n\nprint(final_result.shape)\nfinal_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# confirming that the predicted images are ordered as in sample submission dataframe\nassert sum(sample_submission['image_name'] == final_result['image_name']) == 61191","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing the .jpg extension from 'iamge_name' column\nfinal_result['image_name'] = final_result['image_name'].apply(lambda x: x[:-4])\nfinal_result.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_result.to_csv('seventh_submission.csv', index=False) # saving the predictions","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}